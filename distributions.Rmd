---
title: "Distributions"
author: "Rob van der Nagel"
date: "12-3-19"
output:
  html_notebook:
    df_print: paged
    highlight: pygments
    toc: yes
    toc_float:
      collapsed: false
  html_document:
    highlight: pygments
    toc: yes
  pdf_document:
    highlight: pygments
    toc: yes
urlcolor: blue
---

```{r, include = F}
rm(list = ls())
source('lib/utils.r')
```
```{r, child = c('lib/macros.tex')}
```

# Overview

Each random station has a unique distribution.
Multiple stackers can have the same distribution.
Spelling: $ X \ DistAs {} V $ for 'the $ X $ random has distribution $ V $'.

Important characteristics of a distribution (or a random list with this distribution):

* Values: discreet or continuous.
* Probability function (discreet) or probability density function (continuous).
* Probability distribution function of stochast $ X $: $ F: \ Real \ to [0,1] $ with $ F (x) = \ Proba (X \ le {} x) $.
* Quantiling: The 'inverse' of the probability distribution function $ \ Quantile (p): = \ max \ {y \ mid {} F (x) \ le {} p \} $.
* Moments: Expected value $ \ Expect (X) $, variance $ \ Variance (X): = \ Expect (X- \ Expect (X)) ^ 2 $, ....

## Relationships between distributions

Already known:

* Discreet uniform
* Bernoulli
* Binomial
* Geometric
* Poisson

* Continuous uniform
* Normal (Gaussian)
* Exponential
* Student t (for t test)

Later in this course:

* Erlang
* Chi square
* Gamma
* F distribution

See also the overview [M&R, Appendix A, Table I] ().

Divisions with their density function as memory support, relationships affected but without transformations:
`` `{r, echo = F}
knitr :: include_graphics (path = './img/relatie_dichtheid_univariat.png')
`` `

Relationship between univariate distributions of [wikipedia] (https://en.wikipedia.org/wiki/Relationships_among_probability_distributions), with the transformations between distributions:
`` `{r, echo = F}
knitr :: include_graphics (path = './img/relatie_univariate_verdelingen.jpg')
`` `

# Divisions

## Bernoulli

* Values: $ \ Set {0,1} $.
* Parameters: $ p \ in [0,1] $.
* Distribution: $ \ Bernoulli {p} $.
* Application: Shed a coin. Answer a yes-no question. Switched on / off.
* Reference: [M&R, section 3-6] (). [Wikipedia] (https://en.wikipedia.org/wiki/Bernoulli- distribution).
* Expected value: $ p $.
* Variance: $ p (1-p) $.

Because there are only two possible outcomes, we only calculate the number of outcomes and plot the ratios.
```{r}
p <- 0.45
sample. variable <- 200
sample <- rbinom (sample.size, size = 1, prob = p)
table (sample)
summary (sample)
bar plot (height = table (sample))
bar plot (height = table (sample) / sample. variable, ylim = c (0.1))
`` `

## Uniform or equal distribution (discreet)

* Parameters: $ a, b \ in \ Int $ with $ a \ le {} b $.
* Distribution: $ \ Uniform {\ Set {a, a + 1, \ dotsc, b}} $.
* Stochast / carrier distribution values: $ \ Set {a, a + 1, \ dotsc, b} $.
* Application: With equal opportunity finally draw many possibilities.
* Reference: [M&R, section 3-5] () [Wikipedia] (https://en.wikipedia.org/wiki/Uniforme_ Distribution_ (discreet)).
* Probability function: $ \ frac {1} {b-a + 1} $ on $ \ Set {a, a + 1, \ dotsc, b} $.
* Expected value: $ \ frac {b-a} {2} $.
* Variance: $ \ frac {(b-a + 1) ^ 2 - 1} {12} $.

`` `{r, include = F}
dunifdisc <-function (x, min = 0, max = 1) ifelse (x> = min & x <= max & round (x) == x, 1 / (max-min + 1), 0)
punifdisc <-function (q, min = 0, max = 1) ifelse (q <min, 0, ifelse (q> = max, 1, (floor (q) -min + 1) / (max-min + 1) ))
qunifdisc <-function (p, min = 0, max = 1) floor (p * (max-min + 1))
runifdisc <-function (n, min = 0, max = 1) sample (min: max, n, replace = T)
`` `

`` `{r}
a <- -2
b <- 5
sample. variable <- 25
sample <- sample (a: b, sample.size, replace = T)
`` `
The distribution is discreet. Therefore, two data points with probability $ 1 / n $ (here $ 1 / `r sample.size` $) can be the same. So for each possible value in $ \ Set {`r a`,` r a + 1`, \ dotsc, `r b`} $ we plot the share of data points with this value (= number divided by $ n $).

`` `{r}
plot.domain <- a: b
plot (plot.domain, punifdisc (plot.domain, min = a, max = b), type = 'p', ylim = c (0.1), main = "Discrete uniform distribution", xlab = "values", ylab = "chance")
points (plot.domain, dunifdisc (plot.domain, min = a, max = b), col = 'orange')
lines (seq (a, b, length.out = 100), rep (1 / (b-a + 1), 100), col = 'orange')
sample values ​​<- sort (unique (sample))
sampler.teller <- table (sampler)
points (sample value, sample value, counter / sample value, col = 'red', pch = 'x')
sampled.cumcounts <- cumsum (sampled.teller)
points (sample values, cumsum (sample counter) / sample value, col = 'green', pch = 'x')
`` `

## Uniform or equal distribution (continuous)

* Values: $ [a, b] $.
* Parameters: $ a, b \ in \ Real $ with $ a \ le {} b $.
* Distribution: $ \ Uniform {[a, b]} $.
* Application: Pull out of limited interval with equal chance.
* Reference: [M&R, section 4-5] () [Wikipedia] (https://en.wikipedia.org/wiki/Uniforme_ Distribution_ (continuous)).
* Expected value: $ \ frac {b-a} {2} $.
* Variance: $ \ frac {(b-a) ^ 2} {12} $.

Because the distribution is continuous, with probability $ 1 $ no two data points are equal. So we also plot where the data itself is in blue.

`` `{r}
a <- -2
b <- 5
sample. variable <- 25
sample <- runif (sample.size, min = a, max = b)
plot.domain <- seq (a-2, b + 2, length.out = 500)
plot (plot.domain, punif (plot.domain, min = a, max = b), type = 'l', ylim = c (0.1), main = "Continuous uniform distribution", xlab = "values", ylab = "chance")
lines (plot.domain, dunif (plot.domain, min = a, max = b), col = 'orange')
points (sample, rep (1 / (b-a), sample.size), col = 'blue')
plot (ecdf (sample), col = 'green', add = T)
Sample Density Fct <- Density (Sample, from = a, to = b)
lines (sample density density, col = "red")
sample.tightnessfct.unlimited <- density (sample)
lines (sample density density unlimited, col = "red", lty = "dashed")
```

## Binomial

* Values: $ \ Set {0,1, \ dotsc, n} $.
* Parameters: $ n \ in \ Nat $, $ p \ in [0,1] $.
* Distribution: $ \ Binomial {n, p} $.
* Application: Add up the number of successes of $ n $ independent repetitions of an experiment. Add number of hits from salvo.
* Reference: [M&R, section 3-6] () [Wikipedia] (https://en.wikipedia.org/wiki/Binomiale_ Distribution).
* Expected value: $ np $.
* Variance: $ np (1-p) $.
* Bernoulli if $ n = 1 $: $ \ Binomial {1, p} = \ Bernoulli {p} $.
* $ \ Binomial {n, p} $ random as the sum of $ n $ independent $ \ Bernoulli {p} $ random.

`` `{r}
p <- 0.4
n <- 20
sample. variable <- 25
sample <- rbinom (sample.size, size = n, prob = p)
plot.domain <- 0: n
plot (plot.domain, pbinom (plot.domain, size = n, prob = p), type = 'p', pch = 'x', ylim = c (0.1), main = "binomial distribution", xlab = "values", ylab = "opportunity")
points (plot.domain, dbinom (plot.domain, size = n, prob = p), col = 'orange')
sample values ​​<- sort (unique (sample))
sampler.teller <- table (sampler)
points (sample value, sample value, counter / sample value, col = 'red', pch = 'x')
sampled.cumcounts <- cumsum (sampled.teller)
points (sample values, cumsum (sample counter) / sample value, col = 'green', pch = 'x')
`` `

## Poisson

* Values: $ \ Nat = \ Set {0,1,2,3,4, \ dotsc} $.
* Parameters: $ \ lambda \ in [0, \ infty [$.
* Distribution: $ \ Poisson {\ lambda} $.
* Application: Number of rare independent events.
* Reference: [M&R, section 3-9] () [Wikipedia] (https://en.wikipedia.org/wiki/Poisson distribution).
* Expected value: $ \ lambda $.
* Variance: $ \ lambda $.
* As a limit: $ \ Binomial {n, \ frac {\ lambda} {n}} \ xrightarrow [n \ to \ infty] {} \ Poisson {\ lambda} $.
`` `{r}
lambda <- 3
sample. variable <- 25
sample <- rpois (sample. variable, lambda = lambda)
plot.domain <- 0: max (sample, 5 * lambda)
plot (plot.domain, ppois (plot.domain, lambda = lambda), type = 'p', pch = 'x', ylim = c (0.1), main = "Poisson distribution", xlab = "values" , ylab = "chance")
points (plot.domain, dpois (plot.domain, lambda = lambda), col = 'orange')
sample values ​​<- sort (unique (sample))
sampler.teller <- table (sampler)
points (sample value, sample value, counter / sample value, col = 'red', pch = 'x')
sampled.cumcounts <- cumsum (sampled.teller)
points (sample values, cumsum (sample counter) / sample value, col = 'green', pch = 'x')
`` `

## Normal

* Values: $ \ Real $.
* Parameters: $ \ mu \ in \ Real $, $ \ sigma \ in [0, \ infty [$.
* Distribution: $ \ Normal {\ mu, \ sigma} $.

* Application: Limit form of sum of many small independent effects. Central limit theorem!
* Reference: [M&R, section 4-6] () [Wikipedia] (https://en.wikipedia.org/wiki/Normale_ Distribution).
* Expected value: $ \ mu $.
* Variance: $ \ sigma $.
* Linearity: $ X \ DistAs \ Normal {\ mu, \ sigma} $, $ a \ in \ Real $, $ b \ in [0, \ infty [$, then $ aX + b \ DistAs \ Normal {a \ mu + b, \ Modulus {a} \ sigma} $.
* Standard normal distribution: $ \ Normal {0.1} $ with probability distribution function $ \ SNDF $: $ \ SNDF (x): = \ Proba (X \ le {} x) $ as $ X \ DistAs {} \ Normal {0, 1} $. Values ​​of $ \ SNDF $ are in [M&R, Appendix A, Table III] ().
* Other name: Gaussian distribution, Bell curve (distribution function).

`` `{r}
mu <- 2
sigma <- 3
sample.size <- 30
sample <- rnorm (sample.size, mean = mu, sd = sigma)
plot.domain <- seq (mu-4 * sigma, mu + 4 * sigma, length.out = 500)
plot (plot.domain, pnorm (plot.domain, mean = mu, sd = sigma), type = 'l', ylim = c (0.1), main = "Normal distribution", xlab = "values", ylab = "opportunity")
polygon (c (min (plot.domain), plot.domain, max (plot.domain)), c (0, dnorm (plot.domain, mean = mu, sd = sigma), 0), col = "orange" , border = NA)
points (sample, rep (0, sample, variable), col = 'blue', pch = 'x')
plot (ecdf (sample), col = 'green', add = T)
Sample Density Fct <- Density (Sample)
lines (sample density density, col = "red")
`` `
Suppose $ (X_n) _ {n = 1} ^ \ infty $ independently with the same distribution $ V $ and $ \ Expect (X_1) = \ mu $ and $ \ Variance (X_1) = \ sigma $.
The "strong law of large numbers" says that
$$ \ lim_ {n \ to \ infty} \ frac {1} {n} \ sum_ {i = 1} ^ n X_i = \ mu \,. $$
The _central limit theorem_ [M&R, section 4.7] () [Wikipedia] (https://en.wikipedia.org/wiki/Centrale_limietstelling)
shows the fluctuations around this limit.
$$ \ lim_ {n \ to \ infty} \ frac {\ left (\ frac {1} {n} \ sum_ {i = 1} ^ n \ right) - n \ mu} {\ sigma \ sqrt {n} } \ DistAs \ Normal {0.1} \,. $$

An example with $ V = \ Uniform {\ Set {-2, \ dotsc, 4}} $.

`` `{r}
clt.n <- 1000
clt.data <- sample (-2: 4, clt.n, replace = T)
clt.deelsums <- cumsum (clt.data)
clt.mean <- 1
clt.mean.trend <- (1: clt.n) * clt.mean
clt.var <- ((4 - (- 2) -1) ^ 2-1) / 12
clt.sigma <- sqrt (clt.var)
clt.3sigma.upper <- clt.mean.trend + sqrt (1: clt.n) * 3 * clt.sigma
clt.3sigma.lower <- clt.mean.trend - sqrt (1: clt.n) * 3 * clt.sigma
clt.ylim <- range (clt.deelsums, clt.3sigma.upper, clt.3sigma.lower)
plot (1: clt.n, clt.deelums, type = 'l', ylim = clt.ylim, main = 'Partial sums and 3 sigma deviations')
lines (1: clt.n, clt.mean.trend, col = 'green')
lines (1: clt.n, clt.3sigma.upper, col = 'blue')
lines (1: clt.n, clt.3sigma.lower, col = 'blue')
`` `

The black curve has a distribution close to $ \ Normal {`r clt.n * clt.mean`,` r clt.var * sqrt (clt.n) `} $ at its right end point.

## Geometric

* Values: $ \ Nat = \ {0,1,2,3,4, \ dotsc \} $.
* Parameters: $ p \ in {}] 0,1] $.
* Distribution: $ \ Geometric {p} $.

* Application: Number of repetitions of independent Bernoulli with success rate $ 1-p $ up to and including the first failure.
* Reference: [M&R, section 3-7] () [Wikipedia] (https://en.wikipedia.org/wiki/Geometric_division).
* Expected value: $ \ frac {1} {p} $.
* Variance: $ \ frac {1-p} {p ^ 2} $.
* Via Bernoulli: $ X_i $ iid $ \ Bernoulli {p} $, then $ Y: = \ min \ Set {i \ mid {} X_i = 0} \ DistAs \ Geometric {p} $.
* Memoryless: $ X \ DistAs \ Geometric {p} $, then $ \ Proba (X \ ge n \ mid {} X \ ge m) = \ Proba (X \ ge nm) $ (if $ m \ le { } n $).
`` `{r}
p <- 0.2
sample. variable <- 25
sample <- rgeom (sample.size, prob = p)
plot.domain <- 0: max (sample, 5 * lambda)
plot (plot.domain, pgeom (plot.domain, prob = p), type = 'p', pch = 'x', ylim = c (0.1), main = "Geometric distribution", xlab = "values" , ylab = "chance")
points (plot.domain, dgeom (plot.domain, prob = p), col = 'orange')
sample values ​​<- sort (unique (sample))
sampler.teller <- table (sampler)
points (sample value, sample value, counter / sample value, col = 'red', pch = 'x')
sampled.cumcounts <- cumsum (sampled.teller)
points (sample values, cumsum (sample counter) / sample value, col = 'green', pch = 'x')
`` `

## Exponential

* Parameters: $ \ lambda \ in [0, \ infty [$.
* Distribution: $ \ Exponential {\ lambda} $.
* Values: $ [0, \ infty [$.
* Application: Memory-free timer for simulations (queues, ...). Split times between many independent callers.
* Reference: [M&R, section 4-8] () [Wikipedia] (https://en.wikipedia.org/wiki/Exponenti%C3%ABle_ Distribution).
* Expected value: $ 1 / \ lambda $.
* Variance: $ 1 / \ lambda ^ 2 $.
* If limit: $ X_n \ DistAs \ Geometric {\ frac {\ lambda} {n}} $, then $ \ frac {1} {n} X_n \ xrightarrow [n \ to \ infty] {} Y \ DistAs \ Geometric {\ lambda} $.
* Memoryless: $ X \ DistAs \ Exponential {\ lambda} $, then $ \ Proba (X \ ge b \ mid {} X \ ge a) = \ Proba (X \ ge ba) $ (if $ a \ le {} b $).

`` `{r}
lambda <- 0.3
sample.size <- 30
sample <- rexp (sample. variable, rate = lambda)
plot.domain. upper limit <- max (sample, 4 / lambda)
plot.domain <- seq (0, plot.domain. upper limit, length.out = 500)
plot (plot.domain, pexp (plot.domain, rate = lambda), type = 'l', ylim = c (0.1), main = "Exponential distribution", xlab = "values", ylab = "probability" )
polygon (c (min (plot.domain), plot.domain, max (plot.domain)), c (0, dexp (plot.domain, rate = lambda), 0), col = "orange", border = NA )
points (sample, rep (0, sample, variable), col = 'blue', pch = 'x')
plot (ecdf (sample), col = 'green', add = T)
sample.densityfct <- density (sample, from = 0, to = plot.domain. upper limit)
lines (sample density density, col = "red")
`` `
